Dataset
Synthetic Data Generation
The project does not use real-world data.All inputs are generated by data_generator.py, which creates:

Short biographical texts (doc_001.txt … doc_012.txt)
Corresponding ground truth annotations (ground_truth.json) containing:
Entity definitions
Relations (e.g., works_for, studied_at, lives_in)
Personality data (Big Five + traits)



How It Works
Each biography is template-based and includes:

A person, organization, university, and location.
Two to three personality traits linked to underlying Big Five scores.
Factual statements for relation extraction.

Example:
Jonas Park is a curious and resilient product designer at Orion Systems.He studied at Eastvale Institute of Technology and now lives in Maple Grove.He often coordinates sprints with colleagues.
Ground Truth Entry:
{
  "entities": [...],
  "relations": [["p001", "works_for", "o002"], ["p001", "studied_at", "u003"], ...],
  "personality": {
    "p001": {
      "big_five": {...},
      "traits": ["curious", "resilient"]
    }
  }
}

This setup ensures reproducibility and clear evaluation of extraction accuracy.
Setup Instructions
1. Environment Setup
Create a Python virtual environment and install dependencies.
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

Ensure you have:

Python 3.10+
Access to the OpenAI API key (for relation and personality inference)

Add your key as an environment variable:
export OPENAI_API_KEY="your_api_key_here"

2. Install spaCy Model
The transformer-based English model can be installed as follows:
pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.7.3/en_core_web_trf-3.7.3-py3-none-any.whl

Execution
Step 1. Generate Synthetic Dataset
python src/data_generator.py

This creates:

data/synthetic_texts/doc_XXX.txt
data/synthetic_texts/ground_truth.json

Step 2. Run Preprocessing and Entity Extraction
python src/preprocessing.py

Generates outputs/entities.json with detected entities and sentences.
Step 3. Run Relation Extraction
python src/relation_extraction.py

Uses the OpenAI LLM to infer subject–predicate–object triples.The schema restricts relations to:

works_for
studied_at
lives_in
collaborates_with
reports_to

A precision-focused filter validates each triple.
Step 4. Run Personality Inference
python src/personality_inference.py

Prompts the LLM to estimate Big Five scores (0–1 scale) and select traits from an approved list.
Step 5. Build the Knowledge Graph
python src/kg_builder.py

Creates and exports:

knowledge_graph.gexf
knowledge_graph.graphml

Step 6. Evaluate Performance
python src/evaluation.py

Compares predictions against ground truth and outputs:outputs/evaluation_metrics.json
Results
Evaluation Metrics Summary



Component
Precision
Recall
F1 / MAE / Jaccard



Entity Extraction
1.00
1.00
1.00


Relation Extraction
0.83
0.77
0.80


Personality Inference (MAE)
—
—
0.205


Personality Traits (Jaccard)
—
—
0.63


Key Findings
Entity Extraction

Perfect precision and recall due to structured synthetic text.

Relation Extraction

Achieved F1 = 0.80 after enforcing schema restrictions and adding post-filter validation.
Clean, type-consistent triples with minimal noise.

Personality Inference

MAE improved from 0.23 → 0.205 through prompt calibration and personality-text alignment.
Jaccard stabilized around 0.63 due to synonym variation (e.g., “organized” vs. “meticulous”).
